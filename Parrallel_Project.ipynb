{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parrallel_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow-estimator\n",
        "!pip install tensorflow-estimator\n",
        "!pip uninstall keras\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "jKaK9lz2H6C4",
        "outputId": "f117c5fa-f6b3-4704-e965-0396b64d52ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow-estimator 2.8.0\n",
            "Uninstalling tensorflow-estimator-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_estimator-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "Collecting tensorflow-estimator\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 4.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator\n",
            "26.0\n",
            "Successfully installed tensorflow-estimator-2.8.0\n",
            "Found existing installation: keras 2.8.0\n",
            "Uninstalling keras-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/keras-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled keras-2.8.0\n",
            "Collecting keras\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed keras-2.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qjyv-7QKO8m"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "import threading\n",
        "\n",
        "# baseline cnn model for mnist\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
        "import timeit\n",
        "\n",
        "\n",
        "\n",
        "scores = np.array([[0.0 for i in range(5)] for j in range(11)])\n",
        "histories = np.array([[Sequential() for i in range(5)] for j in range(11)])\n",
        "models = np.array([[Sequential() for i in range(5)] for j in range(11)])\n",
        "bPredicts = np.array([[[0 for i in range(10)] for k in range(10002)] for j in range(5)])\n",
        "cPredicts = np.array([[0 for i in range(10002)] for j in range(5)])\n",
        "\n",
        "def evaluate_model(dataX, dataY, layerNum, lossType, layer2Count, index, n_folds=5):\n",
        "\tglobal scores\n",
        "\tglobal histories\n",
        "\tglobal models\n",
        "\tscorez, historiez, modelz = list(), list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\tprint(index)\n",
        "\t\tmodel = define_model(layerNum, lossType, layer2Count)\n",
        "\t\t# select rows for train and test\n",
        "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# stores scores\n",
        "\t\tmodelz.append(model)\n",
        "\t\tscorez.append(acc)\n",
        "\t\thistoriez.append(history)\n",
        "\tfor i in range(5):\n",
        "\t\tscores[index][i] = scorez[i]\n",
        "\t\thistories[index][i] = historiez[i]\n",
        "\t\tmodels[index][i] = modelz[i]\n",
        "\treturn\n",
        "\n",
        "def evaluate_model_parallel(dataX, dataY, layerNum, lossType, layer2Count, index, n_folds=5):\n",
        "\tglobal scores\n",
        "\tglobal histories\n",
        "\tglobal models\n",
        "\tscorez, historiez, modelz = list(), list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\tprint(index)\n",
        "\t\tmodel = define_model(layerNum, lossType, layer2Count)\n",
        "\t\tmodel = multi_gpu_model(model,gpus=2)\n",
        "\t\t# select rows for train and test\n",
        "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# stores scores\n",
        "\t\tmodelz.append(model)\n",
        "\t\tscorez.append(acc)\n",
        "\t\thistoriez.append(history)\n",
        "\tfor i in range(5):\n",
        "\t\tscores[index][i] = scorez[i]\n",
        "\t\thistories[index][i] = historiez[i]\n",
        "\t\tmodels[index][i] = modelz[i]\n",
        "\treturn\n",
        "\n",
        "\n",
        "def define_model(layerNum, lossType, layer2Count):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(layer2Count, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(layerNum, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss=lossType, metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "def summarize_diagnostics(histories):\n",
        "\tfor i in range(len(histories)):\n",
        "\t\t# plot loss\n",
        "\t\tplt.subplot(2, 1, 1)\n",
        "\t\tplt.title('Cross Entropy Loss')\n",
        "\t\tplt.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "\t\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "\t\t# plot accuracy\n",
        "\t\tplt.subplot(2, 1, 2)\n",
        "\t\tplt.title('Classification Accuracy')\n",
        "\t\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "\t\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "\tplt.show()\n",
        " \n",
        "def summarize_performance(scores):\n",
        "\t# print summary\n",
        "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "\t# box and whisker plots of results\n",
        "\tplt.boxplot(scores)\n",
        "\tplt.show()\n",
        "\n",
        "def predict_and_print(img,imgy,num):\n",
        "  global bPredicts\n",
        "  global cPredicts\n",
        "  for i in range(5):\n",
        "    print(num)\n",
        "    if(num < 10):\n",
        "      bPredicts[i][0][num] = timeit.default_timer()\n",
        "    else:\n",
        "      cPredicts[i][0] = timeit.default_timer()\n",
        "    model = load_model('/content/drive/MyDrive/PPmodels/PPmodel'+str(num+1)+'-'+str(i)+'.h5')\n",
        "    for j in range(len(img)):\n",
        "      if j%100 == 0:\n",
        "        print(j/100)\n",
        "      temp = img[j].reshape(1,28,28,1)\n",
        "      if(num != 10):\n",
        "        bPredicts[i][j+1][num] = np.argmax(model.predict(temp))\n",
        "      else:\n",
        "        cPredicts[i][j+1] = np.argmax(model.predict(temp))\n",
        "    if(num != 10):\n",
        "      bPredicts[i][len(img)+1][num] = timeit.default_timer()\n",
        "    else:\n",
        "      cPredicts[i][len(img)] = timeit.default_timer()\n",
        "    #print(xTest[0])\n",
        "  return\n",
        "\n",
        " \n",
        "__name__ == '__main__'\n",
        "global scores\n",
        "global histories\n",
        "global bPredicts\n",
        "global cPredicts\n",
        "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
        "    \n",
        "sizes = [0 for i in range(10)]\n",
        "yTrain = to_categorical(yTrain)\n",
        "yTest = to_categorical(yTest)\n",
        "yTrainSep = np.array([[[0 for j in range(2)] for i in range(len(yTrain))] for k in range(10)], dtype = 'float32')\n",
        "yTestSep = np.array([[[0 for j in range(2)] for i in range(len(yTest))] for k in range(10)], dtype = 'float32')\n",
        "for j in range(10):\n",
        "  for i in range(len(yTrain)):\n",
        "    if(yTrain[i][j] == 0):\n",
        "      yTrainSep[j][i][1] = 1\n",
        "    else:\n",
        "      yTrainSep[j][i][0] = 1\n",
        "for j in range(10):\n",
        "  for i in range(len(yTest)):\n",
        "    if(yTest[i][j] == 0):\n",
        "      yTestSep[j][i][1] = 1\n",
        "    else:\n",
        "      yTestSep[j][i][0] = 1\n",
        "   \n",
        "#modelSep = []\n",
        "#for i in range(10):\n",
        "#  modelSep.append(define_model(2,'binary_crossentropy',100))\n",
        "#modelSep.append(define_model(10,'categorical_crossentropy',100))\n",
        "\n",
        "xTrain = xTrain.reshape((xTrain.shape[0], 28, 28, 1))\n",
        "xTest = xTest.reshape((xTest.shape[0], 28, 28, 1))\n",
        "#for i in range(len(xTest)):\n",
        "  #xTest[i] = xTest[i].reshape(28,28,1)\n",
        "print(xTest[0].shape)\n",
        "xTrain, xTest = prep_pixels(xTrain, xTest)\n",
        "testImage = xTest[0]\n",
        "testImage = testImage.reshape(28,28,1)\n",
        "#print('PPmodel'+str(0)+'-'+str(1)+'.h5')\n",
        "t = [threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[0],2,'binary_crossentropy',10,0)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[1],2,'binary_crossentropy',10,1)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[2],2,'binary_crossentropy',10,2)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[3],2,'binary_crossentropy',100,3)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[4],2,'binary_crossentropy',100,4)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[5],2,'binary_crossentropy',100,5)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[6],2,'binary_crossentropy',100,6)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[7],2,'binary_crossentropy',100,7)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[8],2,'binary_crossentropy',100,8)),threading.Thread(target=evaluate_model, args=(xTrain, yTrainSep[9],2,'binary_crossentropy',100,9)),threading.Thread(target=evaluate_model, args=(xTrain, yTrain,10,'categorical_crossentropy',100,10))]\n",
        "s = [threading.Thread(target=predict_and_print, args=(xTest,yTestSep[0],0)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[1],1)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[2],2)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[3],3)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[4],4)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[5],5)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[6],6)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[7],7)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[8],8)),threading.Thread(target=predict_and_print, args=(xTest,yTestSep[9],9)),threading.Thread(target=predict_and_print, args=(xTest,yTest,10))]\n",
        "for i in range(10):\n",
        "  #if(i > 5):\n",
        "    evaluate_model(xTrain, yTrainSep[i],2,'binary_crossentropy',10,i)\n",
        "    #for j in range(5):\n",
        "      #models[i][j].save('PPmodel'+str(i)+'-'+str(j)+'.h5')\n",
        "#evaluate_model(xTrain, yTrain,10,'categorical_crossentropy',100,10)\n",
        "#for j in range(5):\n",
        "  #models[10][j].save('PPmodel'+str(10)+'-'+str(j)+'.h5')\n",
        "#evaluate_model(xTrain, yTrain,10,'categorical_crossentropy',100,10)\n",
        "#for j in range(5):\n",
        "#  models[10][j].save('PPmodel'+str(11)+'-'+str(j)+'.h5')\n",
        "\n",
        "#summarize_diagnostics(histories[0])\n",
        "#summarize_mance(scores[0])\n",
        "#for i in range(10):\n",
        "#  t[i].start()\n",
        "#  t[i].join()\n",
        "\n",
        "#for i in range(1):\n",
        "\n",
        "#print(scores[0])\n",
        "#print(np.argmax(models[0][0].predict(testImage)))\n",
        "#print(xTest[0])\n",
        "#for i in range(10):\n",
        "  #s[i].start()\n",
        "  #s[i].join()\n",
        "  \n",
        "\n",
        "#results = np.array([[[0 for k in range(3)] for i in range(2)] for j in range(5)])\n",
        "#for i in range(5):\n",
        "#  for j in range(10):\n",
        "#    temp = bPredicts[i][len(yTest)+1][j] - bPredicts[i][0][j]\n",
        "#    if temp > results[i][0][0]:\n",
        "#      results[i][0][0] = temp\n",
        "#  for j in range(len(yTest)):\n",
        "#    for k in range(10):\n",
        "#      counter = 0\n",
        "#      if(bPredicts[i][j+1][k] == 0):\n",
        "#        counter += 1\n",
        "#      if(counter == 1):\n",
        "#        if np.argmin(bPredicts[i][j+1]) == np.argmax(yTest[j]):\n",
        "#          results[i][0][1] += 1\n",
        "#        else:\n",
        "#          results[i][0][2] += 1\n",
        "#      else:\n",
        "#        results[i][0][2] += 1\n",
        "#predict_and_print(xTest,yTest,10)\n",
        "#for i in range(5):\n",
        "#  results[i][1][0] = cPredicts[i][len(yTest)+1] - cPredicts[i][0]\n",
        "#  for j in range(len(yTest)):\n",
        "#    if(cPredicts[i][j+1] == np.argmax(yTest[j])):\n",
        "#      results[i][1][1] += 1\n",
        "#    else:\n",
        "#      results[i][1][2] += 2\n",
        "\n",
        "#print(results)\n"
      ]
    }
  ]
}